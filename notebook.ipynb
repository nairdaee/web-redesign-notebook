{"cells":[{"source":"# Measuring the impact of a website redesign the Bayesian way\n\n## ðŸ“– Background\nYou work for an early-stage startup in Germany. Your team has been working on a redesign of the landing page. The team believes a new design will increase the number of people who click through and join your site. \n\nThey have been testing the changes for a few weeks and now they want to measure the impact of the change and need you to determine if the increase can be due to random chance or if it is statistically significant.\n\n![cover](cover.png)\n\nThe figure above captures our result in a single picture. Do keep reading to understand it!","metadata":{},"id":"9a9ada08-c9f0-466f-91a0-265fa539f9f5","cell_type":"markdown"},{"source":"## ðŸ’¾ The data\nThe team assembled the following file:\n\n#### Redesign test data\n- \"treatment\" - \"yes\" if the user saw the new version of the landing page, no otherwise.\n- \"new_images\" - \"yes\" if the page used a new set of images, no otherwise.\n- \"converted\" - 1 if the user joined the site, 0 otherwise.\n\nThe control group is those users with \"no\" in both columns: the old version with the old set of images.","metadata":{"tags":[]},"id":"10dcc269-3659-4851-99cd-f1ffb7f818aa","cell_type":"markdown"},{"source":"# Ignore installation error messages below, this is all OK for our purposes.\n!pip -qqq --no-color install pymc3 'numpy>=1.15.0,<1.22.0'","metadata":{"executionTime":13157,"lastSuccessfullyExecutedCode":"# Ignore installation error messages below, this is all OK for our purposes.\n!pip -qqq --no-color install pymc3 'numpy>=1.15.0,<1.22.0'"},"id":"c588d72b-b086-486e-9709-bb3382aa5695","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npythonwhat 2.23.1 requires asttokens~=1.1.10, but you have asttokens 2.0.8 which is incompatible.\npythonwhat 2.23.1 requires dill~=0.2.7.1, but you have dill 0.3.5.1 which is incompatible.\npythonwhat 2.23.1 requires jinja2~=2.10, but you have jinja2 3.1.2 which is incompatible.\n"}]},{"source":"import pandas as pd\nimport numpy as np\nimport pymc3 as pm\nimport scipy.stats as stats\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\n# https://viscid-hub.github.io/Viscid-docs/docs/dev/styles/bmh.html\nBMH_COLORS = ['#348ABD', '#A60628', '#7A68A6', '#467821']\n\nnp.random.seed(44)\nprint('Numpy version:', np.__version__)\nprint('PyMC3 version:', pm.__version__)","metadata":{"executionTime":7137,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np\nimport pymc3 as pm\nimport scipy.stats as stats\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\n# https://viscid-hub.github.io/Viscid-docs/docs/dev/styles/bmh.html\nBMH_COLORS = ['#348ABD', '#A60628', '#7A68A6', '#467821']\n\nnp.random.seed(44)\nprint('Numpy version:', np.__version__)\nprint('PyMC3 version:', pm.__version__)"},"id":"8b30a43a-a42d-4164-b5a9-7d8b37b6c7bd","cell_type":"code","execution_count":2,"outputs":[{"output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)","Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/__init__.py:115\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m __set_compiler_flags()\n\u001b[1;32m    113\u001b[0m _hotfix_theano_printing()\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gp, ode, sampling\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_trace, save_trace\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracetab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/gp/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#   Copyright 2020 The PyMC Developers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#   Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#   See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#   limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cov, mean, util\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TP, Latent, LatentKron, Marginal, MarginalKron, MarginalSparse\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/gp/gp.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eigh\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_values\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Constant, Covariance\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Zero\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/distributions/__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#   Copyright 2020 The PyMC Developers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#   Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#   See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#   limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shape_utils, timeseries, transforms\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BART\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bound\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/distributions/timeseries.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribution, multivariate\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontinuous\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flat, Normal, get_tau_sigma\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_tuple\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/distributions/distribution.py:45\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m     broadcast_dist_samples_shape,\n\u001b[1;32m     42\u001b[0m     get_broadcastable_dist_samples,\n\u001b[1;32m     43\u001b[0m     to_tuple,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     46\u001b[0m     ContextMeta,\n\u001b[1;32m     47\u001b[0m     FreeRV,\n\u001b[1;32m     48\u001b[0m     Model,\n\u001b[1;32m     49\u001b[0m     MultiObservedRV,\n\u001b[1;32m     50\u001b[0m     ObservedRV,\n\u001b[1;32m     51\u001b[0m     build_named_node_tree,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_repr_for_variable, get_var_name, hash_key\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvartypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_types, theano_constant\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/model.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorVariable\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayOrdering, DictToArrayBijection\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImputationWarning\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtheanof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m floatX, generator, gradient, hessian, inputvars\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/blocking.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_var_name\n\u001b[1;32m     27\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrayOrdering\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictToArrayBijection\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictToVarBijection\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m VarMap \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVarMap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar, slc, shp, dtyp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymc3/util.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Union\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01marviz\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdill\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/arviz/__init__.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_log(level, msg, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     29\u001b[0m _log \u001b[38;5;241m=\u001b[39m Logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marviz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/arviz/data/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Code for loading and manipulating data structures.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoordSpec, DimSpec, dict_to_dataset, numpy_to_data_array\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_dataset, convert_to_inference_data\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_data_home, list_datasets, load_arviz_data\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InferenceData, concat\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/arviz/data/converters.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_emcee\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_emcee\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_numpyro\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_numpyro\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_pymc3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_pymc3\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_pyro\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_pyro\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_pystan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_pystan\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/arviz/data/io_pymc3.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_pymc3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_pymc3_predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     pymc3_version \u001b[38;5;241m=\u001b[39m \u001b[43mpkg_resources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpymc3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n\u001b[1;32m     10\u001b[0m     PYMC3_V4 \u001b[38;5;241m=\u001b[39m packaging\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mparse(pymc3_version) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m packaging\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pkg_resources\u001b[38;5;241m.\u001b[39mDistributionNotFound:\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:478\u001b[0m, in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    476\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Requirement\u001b[38;5;241m.\u001b[39mparse(dist)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Requirement):\n\u001b[0;32m--> 478\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Distribution):\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected string, Requirement, or Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist)\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:354\u001b[0m, in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m working_set\u001b[38;5;241m.\u001b[39mfind(moduleOrReq) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mrequire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmoduleOrReq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[moduleOrReq]\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:909\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mrequirements):\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;124;03m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 909\u001b[0m     needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m needed:\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(dist)\n","File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:800\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m req:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     dependent_req \u001b[38;5;241m=\u001b[39m required_by[req]\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m VersionConflict(dist, req)\u001b[38;5;241m.\u001b[39mwith_context(dependent_req)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# push the new requirements onto the stack\u001b[39;00m\n\u001b[1;32m    803\u001b[0m new_requirements \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mrequires(req\u001b[38;5;241m.\u001b[39mextras)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n","\u001b[0;31mContextualVersionConflict\u001b[0m: (scipy 1.9.0 (/usr/local/lib/python3.8/dist-packages), Requirement.parse('scipy<1.8.0,>=1.7.3'), {'pymc3'})"],"ename":"ContextualVersionConflict","evalue":"(scipy 1.9.0 (/usr/local/lib/python3.8/dist-packages), Requirement.parse('scipy<1.8.0,>=1.7.3'), {'pymc3'})"}]},{"source":"df = pd.read_csv('./data/redesign.csv')\ndf.head()","metadata":{"executionCancelledAt":1679657201210},"id":"40251159-3eea-47f8-bfb4-09e38d5ced65","cell_type":"code","execution_count":3,"outputs":[]},{"source":"We first verify that there are no missing values to ensure that our analysis is correct.","metadata":{},"id":"1339020b-e458-4690-8d18-29dc0ce1bd52","cell_type":"markdown"},{"source":"df.isnull().any()","metadata":{"executionCancelledAt":1679657201261},"id":"e742cd02-f67a-45a6-a253-81e29326cc21","cell_type":"code","execution_count":4,"outputs":[]},{"source":"For convenience, we convert \"yes\" to a `1` and \"no\" to a `0` so that we can compute statistics.","metadata":{},"id":"3452f476-641f-4d9d-96d4-a1245313e88a","cell_type":"markdown"},{"source":"df['treatment'] = df.treatment.map({'yes': 1, 'no': 0})\ndf['new_images'] = df.new_images.map({'yes': 1, 'no': 0})","metadata":{"executionCancelledAt":1679657201297},"id":"797aafc9-23c3-4d10-b302-aadb6a2bceef","cell_type":"code","execution_count":5,"outputs":[]},{"source":"Looking at the summary statistics, we see that the dataset is balanced in every way, 50% of the dataset has a `treatment` and 50% does not; similarly for `new_images`. In fact, it is balanced across all four groups that we have:\n\n1. group $A$: has `treatment` and has `new_images`.\n2. group $B$: has `treatment`, but no `new_images`.\n3. group $C$: no `treatment`, but has `new_images`.\n4. the $\\mathrm{control}$ group: no `treatment` and no `new_images`.\n\nAlso, observe that the conversion rate across all groups have a mean of 11.3% with a sample standard deviation of 31.7% (which is quite large!).","metadata":{},"id":"6c80e55c-d5b0-4ae6-82a6-f447fc6680c2","cell_type":"markdown"},{"source":"df.describe()","metadata":{"executionCancelledAt":1679657201315},"id":"eabecd0a-be66-4941-af2a-4f116a90e073","cell_type":"code","execution_count":6,"outputs":[]},{"source":"def grouping(row):\n    new_landing = row.treatment\n    new_images = row.new_images\n    if new_landing and new_images:\n        return 'A'\n    elif new_landing and not new_images:\n        return 'B'\n    elif not new_landing and new_images:\n        return 'C'\n    return 'control'\n\ndf['group'] = df.apply(grouping, axis=1)\n\nassert (len(df[df.group == \"A\"]) \n        == len(df[df.group == \"B\"]) \n        == len(df[df.group == \"C\"]) \n        == len(df[df.group == \"control\"]))\n\nprint(f'Size of each group: {len(df[df.group == \"A\"])}')","metadata":{"executionCancelledAt":1679657201340},"id":"37113207-23fe-4b1a-b749-8d53c531684a","cell_type":"code","execution_count":7,"outputs":[]},{"source":"## 1. Observables: analyzing the observed conversion rates for each group\n\nTo get a first picture of the conversion rates of each group, we look at the following normalized countplot. Looking at the \"yes\"-es, we observe that all the test groups $A$, $B$, $C$ seems to improve over the control group. In particular, we see that group $B$ seems to improve the most since it has the highest \"yes\" to \"no\" ratio i.e. the highest conversion rate.","metadata":{},"id":"cf9440a1-770a-454e-bdaa-e6dbbf02e1b5","cell_type":"markdown"},{"source":"_, ax = plt.subplots(figsize=(10, 7))\n\nconversion_count = (df.groupby(['group'])['converted']\n                    .value_counts(normalize=True)\n                    .rename('percentage')\n                    .reset_index())\n\nsns.barplot(data=conversion_count, x='converted', y='percentage', hue='group', ax=ax)\n\nax.set_xlabel('Converted?')\nax.set(xticklabels=['no', 'yes']);","metadata":{"executionCancelledAt":1679657201371},"id":"d02b8ad4-d8fa-46a7-8dfd-5f11b83c0650","cell_type":"code","execution_count":8,"outputs":[]},{"source":"The actual numbers agree with our eye observation. Group $B$ has an observed conversion rate of 12% which is 1.3% more than 10.7%, the observed conversion rate of the control group. Group $A$ and group $C$ on the other hand have approximately a 0.7% and 0.6% increase in its observed conversion rate as compared to the control group's.","metadata":{},"id":"87b1888b-f128-472b-8379-0d84954d83d5","cell_type":"markdown"},{"source":"GROUP_CONV_RATE = {}\n\nprint('Observed conversion rate')\nfor i in range(15):\n    print('-', end='')\nprint()\nfor group in df.group.unique():\n    conv_rate = df[df.group == group].converted.mean()\n    GROUP_CONV_RATE[group] = conv_rate\n    print(f'Group {group}: {conv_rate:.3f}')","metadata":{"executionCancelledAt":1679657201468},"id":"dd1e93e4-46dc-4c32-9b1e-42caaa1d8ea1","cell_type":"code","execution_count":9,"outputs":[]},{"source":"If you like pivot tables, we can also do that and get the same answer by recalling what the groups $A$, $B$, $C$ and $\\mathrm{control}$ means.","metadata":{},"id":"93c382ab-beff-4051-952b-67b594f82fcd","cell_type":"markdown"},{"source":"pd.pivot_table(df,\n               values='converted', \n               index=['treatment'], \n               columns=['new_images'],\n               aggfunc=np.mean)","metadata":{"executionCancelledAt":1679657201484},"id":"5e712515-7ecf-4f93-9330-0689fe248294","cell_type":"code","execution_count":10,"outputs":[]},{"source":"## 2. Measuring success of redesign using Bayesian A/B testing\n\nWe will use Bayesian inference to explain the increase in observed conversion rate of groups $A$, $B$, and $C$ since it has better explainability (among many other advantages) as compared to the frequentist approach using p-values. \n\nWe first define a helper function `from_posterior` which helps us to update our \"prior\" since our dataset is quite large to do Bayesian inference on a small machine.","metadata":{},"id":"943e289f-fbac-4fff-9718-ad3b933472c8","cell_type":"markdown"},{"source":"from pymc3.distributions import Interpolated\n\ndef from_posterior(param, samples):\n    \"\"\"https://docs.pymc.io/en/v3/pymc-examples/examples/pymc3_howto/updating_priors.html\"\"\"\n    smin, smax = np.min(samples), np.max(samples)\n    width = smax - smin\n    x = np.linspace(smin, smax, 100)\n    y = stats.gaussian_kde(samples)(x)\n\n    x = np.concatenate([[x[0] - 3 * width], x, [x[-1] + 3 * width]])\n    y = np.concatenate([[0], y, [0]])\n    return Interpolated(param, x, y)","metadata":{"executionCancelledAt":1679657201508},"id":"b30cdd3d-e1f7-4093-9b8c-b6cf52fd5696","cell_type":"code","execution_count":11,"outputs":[]},{"source":"Below, we extract the group `converted` observations which will be used for inference in the next section.","metadata":{},"id":"c825f4af-4fd3-4cc3-a404-6ff2148b3e82","cell_type":"markdown"},{"source":"def prep_group_data(group_name):\n    return df[df.group == group_name].converted.to_numpy().reshape(-1, 1)\n\ngroup_data = {\n    'A': prep_group_data('A'),\n    'B': prep_group_data('B'),\n    'C': prep_group_data('C'),\n    'control': prep_group_data('control'),\n}","metadata":{"executionCancelledAt":1679657201539},"id":"aca29ff0-6ee1-4313-a3e3-40147941d3a9","cell_type":"code","execution_count":12,"outputs":[]},{"source":"### Thinking how our data is generated\n\nThere are four unknown parameters to infer here â€“ these are the conversion rates of the groups $A$, $B$, $C$, and $\\mathrm{control}$ which are probabilities between 0 and 1. We will label these conversion rates as $p_A$, $p_B$, $p_C$, and $p_{\\mathrm{control}}$ respectively. \n\nSince we do not have any prior belief on these conversion rates, we assume as a starting point that each of these conversion rates is equally likely over all possible values between 0 and 1. That is, for example, our current initial belief is that it is equally likely for $p_A$ to be 0.13 as it is to be 0.97 (these are just random numbers). In Bayesian lingo, this means that we assume a uniform prior over the interval $[0, 1]$ for each of these conversion rates. \n\nWe then incorporate our observed conversion rate using a Bernoulli distribution conditioned on the prior conversion rates. This is where \"training\" happens if we think of Bayesian modelling as training a generic machine learning model. By incorporating observations, we are able to update our prior beliefs into a so-called posterior belief.","metadata":{},"id":"0527dfd8-ce57-459c-82c2-2e0f39543744","cell_type":"markdown"},{"source":"def sample_posterior(data, batch_size=5000):\n    traces = []\n    for i in range(0, len(data), batch_size):\n        batch_data = data[i:i+batch_size]\n        model = pm.Model()\n        with model:\n            # Prior\n            if len(traces) == 0:\n                p = pm.Uniform('p', 0, 1)\n            else:\n                p = from_posterior('p', burned_trace['p'])\n            \n            # Likelihood\n            obs = pm.Bernoulli('obs', p, observed=batch_data)\n        \n            # Inference\n            trace = pm.sample(11000, step=pm.Metropolis())\n            burned_trace = trace[1000:]\n            traces.append(burned_trace)\n    return traces","metadata":{"executionCancelledAt":1679657201591},"id":"c58e36fb-ee16-47f2-97c3-c18c9f663432","cell_type":"code","execution_count":13,"outputs":[]},{"source":"Using the Metropolis inference engine, we sample the posterior distribution of the conversion rates $p_A$, $p_B$, $p_C$ and $p_{\\mathrm{control}}$ which in probabilistic programming lingo is called *traces*.","metadata":{},"id":"8affeb48-542a-400d-a229-d0457ffbbaa5","cell_type":"markdown"},{"source":"import logging\nlogger = logging.getLogger('pymc3')\nlogger.setLevel(logging.ERROR)\n\ntraces_A = sample_posterior(group_data['A'])\ntraces_B = sample_posterior(group_data['B'])\ntraces_C = sample_posterior(group_data['C'])\ntraces_control = sample_posterior(group_data['control'])","metadata":{"executionCancelledAt":1679657201646},"id":"4cd92d86-83ff-43aa-944f-adf994ae990b","cell_type":"code","execution_count":14,"outputs":[]},{"source":"def final_samples(trace):\n    return trace[-1]['p']\n\nfinal_trace = {\n    'A': final_samples(traces_A),\n    'B': final_samples(traces_B),\n    'C': final_samples(traces_C),\n    'control': final_samples(traces_control),\n}","metadata":{"executionCancelledAt":1679657201768},"id":"cfd66f5b-dc2b-41ef-9693-68ca4c6060e4","cell_type":"code","execution_count":15,"outputs":[]},{"source":"We plot the posterior distribution of the four conversion rates we wanted to infer:","metadata":{},"id":"66affd4d-aee4-4155-9227-7c3d233dfd5e","cell_type":"markdown"},{"source":"_, ax = plt.subplots(4, 1, figsize=(10, 10))\n\nax[0].set_title('Posterior distributions of conversion rates $p_A$, $p_B$, $p_C$ and $p_{\\mathrm{control}}$')\n\nfor i, group in enumerate(df.group.unique()):\n    ax[i].set_xlim(0.08, 0.15)\n    \n    group_final_trace = final_trace[group]\n    label = 'posterior of $p_{\\mathrm{' + f'{group}' + '}}$'\n    ax[i].hist(group_final_trace, \n               histtype='stepfilled',\n               bins=100, alpha=0.85, density=True, \n               label=label, color=BMH_COLORS[i])\n    ax[i].vlines(group_final_trace.mean(), 0, 150, color='black', linestyle='--', label='mean')\n    ax[i].legend()\n\nplt.show()","metadata":{"executionCancelledAt":1679657201817},"id":"91fddcf5-4d9a-4916-9058-044f3c251ef1","cell_type":"code","execution_count":16,"outputs":[]},{"source":"To see it more clearly, we plot the difference $\\Delta_A$ (respectively $\\Delta_B$, $\\Delta_C$) between the posterior of the test group $A$ (respectively $B$, $C$) and the posterior of the control group.","metadata":{},"id":"896d4403-bc6d-4acd-99d1-4d7f548dc8d6","cell_type":"markdown"},{"source":"_, ax = plt.subplots(3, 1, figsize=(10, 10))\n\nax[0].set_title('Posterior distributions of conversion rate differences $\\Delta_A$, $\\Delta_B$, $\\Delta_C$')\n\nfor i, group in enumerate(['A', 'B', 'C']):\n    ax[i].set_xlim(-0.02, 0.04)\n    \n    group_delta_trace = final_trace[group] - final_trace['control']\n    label = f'posterior of $\\Delta_{group}$'\n    ax[i].hist(group_delta_trace, \n               histtype='stepfilled',\n               bins=100, alpha=0.85, density=True, \n               label=label, color=BMH_COLORS[i])\n    ax[i].vlines(group_delta_trace.mean(), 0, 150, color='black', linestyle='--', label='mean')\n    ax[i].vlines(0, 0, 150, color='black', alpha=0.2)\n    ax[i].legend()\n\nplt.show()","metadata":{"executionCancelledAt":1679657201889},"id":"c8727945-a234-40ec-b418-19a1c6f7b6a4","cell_type":"code","execution_count":17,"outputs":[]},{"source":"Based on the posterior distributions of conversion rate differences $\\Delta_A$, $\\Delta_B$, $\\Delta_C$, we observe that most of the distribution lies above 0. This implies that each group $A$, $B$ and $C$ is more likely to have a higher conversion rate than the control group. That is, the corresponding website version of groups $A$, $B$ and $C$ respectively are all major improvements over the current version. However, it should be obvious that there's a clear winner: group $B$ seems to be most likely to have a higher conversion rate than the control. \n\nThe actual probabilities of the group are computed below:","metadata":{},"id":"e06ae5e2-f0fe-4ed2-aa24-1a7c152f0624","cell_type":"markdown"},{"source":"for group in ['A', 'B', 'C']:\n    print('Probability that user group {0} has higher conversion rate than control: {1:.3f}'\\\n          .format(group, ((final_trace[group] - final_trace['control']) > 0).mean()))","metadata":{"executionCancelledAt":1679657201902},"id":"83491fd0-a52d-49e5-b78e-80585bf53ba1","cell_type":"code","execution_count":18,"outputs":[]},{"source":"### Conclusion\n\nThe probabilities agree with our observation and discussion. In fact, we have a more granular observation.\n\nGroup $B$ with approximately 0.99 probability is the most likely to have a higher conversion rate than the control. Now group $A$ has a probability of 0.93 which is higher than the probability of group $C$ of 0.9. So it is more likely that user group $A$ has a higher conversion rate than the control, as compared to group $C$. This establishes a hierarchy of website redesign performance as follows:\n\n$B$ is best peforming, followed by $A$, and then lastly $C$.","metadata":{},"id":"141ad908-a8a8-463b-90d9-9dfec205cd87","cell_type":"markdown"},{"source":"## 3. Fresh new landing page, but same good ol' images is the way to go\n\nRecall what the group $A$, $B$ and $C$ means:\n\n- user group $A$: saw the **new** version of the **landing page**, with **new set of images**.\n- user group $B$: saw the **new** version of the **landing page**, with **old set of images**. \n- user group $C$: saw the **old** version of the **landing page**, with **new set of images**.\n- $\\mathrm{control}$ user group: saw the **old** version of **both landing page and set of images**.\n\nSo our conclusion from the previous section suggested that there is a hierarchy of website redesign performance like so:\n\n1. **Best performing**: use the new landing page, but keep the old set of images;\n2. **Second best**: use both the new landing page and new set of images;\n3. **Third best**: use the new set of images, but keep the old landing page.\n\nAnd each of them have more than 90% probability of being better than just using the old landing page and old set of images! So we only have a 10% chance of being wrong if we choose any of them, which is quite a small risk already.","metadata":{"toc-hr-collapsed":true},"id":"3af8aeec-c116-4e4e-be1b-27194796a1fa","cell_type":"markdown"},{"source":"### Conclusion\n\nBut if we need to choose one, just redesign the website using the **new landing page** but maintain the **old set of images**. In this case, we only have a 1% chance of being wrong, a very very tiny risk.","metadata":{},"id":"8da5e2fd-e3a9-4252-b3c2-1be3958b2253","cell_type":"markdown"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}